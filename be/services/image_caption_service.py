# services/image_caption_service.py
import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import os
from googletrans import Translator
import io
from dotenv import load_dotenv

load_dotenv()

class ImageCaptionService:
    """
    L·ªõp n√†y ch·ªãu tr√°ch nhi·ªám:
    - Load m√¥ h√¨nh BLIP v√† Processor t·ª´ local (m·ªôt l·∫ßn duy nh·∫•t).
    - Cung c·∫•p h√†m generate_caption() nh·∫≠n file ·∫£nh t·ª´ controller, tr·∫£ v·ªÅ chu·ªói caption.
    - D·ªãch ch√∫ th√≠ch sang ti·∫øng Vi·ªát.
    """

    _model = None
    _processor = None
    _device = "cuda" if torch.cuda.is_available() else "cpu"

    # ƒê∆∞·ªùng d·∫´n m√¥ h√¨nh
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.abspath(os.path.join(current_dir, ".."))
    _model_path = os.path.join(parent_dir, "pretrain", "blip_trained")

    _is_loading = False
    _translator = Translator()

    @classmethod
    def _load_model_if_needed(cls):
        if cls._model is None or cls._processor is None:
            if cls._is_loading:
                import time
                while cls._is_loading and (cls._model is None or cls._processor is None):
                    time.sleep(0.5)
                return

            cls._is_loading = True
            try:
                if not os.path.exists(cls._model_path):
                    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh: {cls._model_path}")

                print(f"ƒêang t·∫£i m√¥ h√¨nh BLIP t·ª´ {cls._model_path}...")
                cls._processor = BlipProcessor.from_pretrained(cls._model_path, use_fast=True)
                cls._model = BlipForConditionalGeneration.from_pretrained(cls._model_path)
                cls._model = cls._model.to(cls._device)
                cls._model.eval()
                print(f"T·∫£i m√¥ h√¨nh th√†nh c√¥ng tr√™n thi·∫øt b·ªã {cls._device}")
            finally:
                cls._is_loading = False

    @classmethod
    def unload_model(cls):
        if cls._model is not None:
            cls._model = None
            cls._processor = None
            import gc
            gc.collect()
            if cls._device == "cuda":
                torch.cuda.empty_cache()
            print("ƒê√£ gi·∫£i ph√≥ng m√¥ h√¨nh kh·ªèi b·ªô nh·ªõ")

    @classmethod
    def translate_caption(cls, text_en):
        """
        D·ªãch vƒÉn b·∫£n ti·∫øng Anh sang ti·∫øng Vi·ªát.
        """
        try:
            translation = cls._translator.translate(text_en, src='en', dest='vi')
            caption_vi = translation.text
            print("üîÅ D·ªãch sang ti·∫øng Vi·ªát:", caption_vi)
            return caption_vi
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi d·ªãch caption: {e}")
            return text_en

    @classmethod
    def generate_caption_from_binary(cls, image_data, max_length=30, num_beams=5, speak=False):
        """
        T·∫°o caption cho ·∫£nh t·ª´ d·ªØ li·ªáu nh·ªã ph√¢n.
        N·∫øu speak=True, s·∫Ω d·ªãch caption sang ti·∫øng Vi·ªát.
        """
        try:
            cls._load_model_if_needed()

            # Chuy·ªÉn d·ªØ li·ªáu nh·ªã ph√¢n th√†nh ƒë·ªëi t∆∞·ª£ng PIL Image
            image = Image.open(io.BytesIO(image_data)).convert("RGB")
            inputs = cls._processor(image, return_tensors="pt")
            for k, v in inputs.items():
                inputs[k] = v.to(cls._device)

            with torch.no_grad():
                output_ids = cls._model.generate(
                    **inputs,
                    max_length=max_length,
                    num_beams=num_beams,
                    min_length=5
                )

            caption_en = cls._processor.decode(output_ids[0], skip_special_tokens=True)
            print("üì∏ Caption ti·∫øng Anh:", caption_en)

            if speak:
                caption_vi = cls.translate_caption(caption_en)
                return caption_vi

            return caption_en

        except Exception as e:
            print(f"L·ªói khi t·∫°o caption: {e}")
            raise
            
    @classmethod
    def generate_caption_from_image_id(cls, image_id, max_length=30, num_beams=5, speak=False):
        """
        T·∫°o caption cho ·∫£nh t·ª´ ID c·ªßa ·∫£nh trong MongoDB.
        """
        from models.image import Image
        
        image_doc = Image.objects(id=image_id).first()
        if not image_doc:
            raise ValueError("Kh√¥ng t√¨m th·∫•y ·∫£nh v·ªõi ID cung c·∫•p")
            
        return cls.generate_caption_from_binary(image_doc.image_data, max_length, num_beams, speak) 